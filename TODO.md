# TODO

## Performance
- [ ] [candles] Add a config to disable per-trade storage (`Candle.trades`) and avoid `copy.deepcopy` on finalize; use a shallow field copy when trades aren't needed. Est. 1.5x-4x throughput and large memory reduction when trade lists are large. `src/mm_toolbox/candles/base.pyx`, `src/mm_toolbox/candles/time.pyx`, `src/mm_toolbox/candles/tick.pyx`, `src/mm_toolbox/candles/price.pyx`, `src/mm_toolbox/candles/volume.pyx`, `src/mm_toolbox/candles/multi.pyx`
- [ ] [candles] Move accumulation into a C-level struct and only materialize `Candle` objects on emit; reduces Python object churn per trade. Est. 1.3x-2.5x at high tick rates. `src/mm_toolbox/candles/base.pyx`
- [ ] [moving_average] Use typed memoryviews for `initialize()` loops and add `update_batch()` to process arrays in a single C loop. Est. 1.3x-2.5x for large windows/arrays. `src/mm_toolbox/moving_average/sma.pyx`, `src/mm_toolbox/moving_average/wma.pyx`, `src/mm_toolbox/moving_average/ema.pyx`, `src/mm_toolbox/moving_average/tema.pyx`
- [ ] [moving_average] Pass `disable_async=True` to `NumericRingBuffer` and skip allocating `_values` when `is_fast=True`. Est. 1.05x-1.2x per-update in tight loops. `src/mm_toolbox/moving_average/base.pyx`, `src/mm_toolbox/moving_average/sma.pyx`, `src/mm_toolbox/moving_average/wma.pyx`
- [ ] [rounding] Add in-place vector APIs (`bids_into`/`asks_into`/`sizes_into`) to reuse output buffers and avoid allocations. Est. 1.2x-2x for large arrays. `src/mm_toolbox/rounding/rounder.pyx`
- [ ] [orderbook/standard] Keep tick lists sorted incrementally: use `bisect`/`insort` for new ticks and `bisect`+`pop` for removals; skip re-sorting when only existing levels change. Est. 2x-10x for large books with small deltas. `src/mm_toolbox/orderbook/standard/orderbook.py`
- [ ] [orderbook/standard] Add a fast-path in `consume_bbo()` that updates the best tick without full list sorting; use `bisect` only when the new BBO tick isn’t strictly best. Est. 1.2x-3x for BBO-heavy feeds. `src/mm_toolbox/orderbook/standard/orderbook.py`
- [ ] [orderbook/standard] Cache `inv_tick_size`/`inv_lot_size` and compute ticks/lots via `int(price * inv)` for non-negative values to avoid `math.floor` and function calls. Est. 1.05x-1.2x in delta-heavy loops. `src/mm_toolbox/orderbook/standard/orderbook.py`, `src/mm_toolbox/orderbook/standard/level.py`
- [ ] [orderbook/standard] Add optional `depth` args to `get_asks/get_bids/iter_asks/iter_bids` and use slicing/`itertools.islice` to avoid full list materialization for shallow queries. Est. 1.2x-5x when depth ≪ book size. `src/mm_toolbox/orderbook/standard/orderbook.py`
- [ ] [websocket] Replace `_unfin_msg_buffer` bytes concatenation with a `bytearray` (or list of memoryviews) to avoid repeated realloc/copy on fragmented frames. Est. 1.2x-3x for large fragmented payloads. `src/mm_toolbox/websocket/connection.pyx`
- [ ] [websocket] Use picows `send_reuse_external_bytearray()` for outbound frames when a buffer has ≥14 bytes headroom; fall back to `send()` for normal bytes. Est. 1.1x-1.5x for large payloads and high send rates. `src/mm_toolbox/websocket/connection.pyx`, `.venv/lib/python3.13/site-packages/picows/picows.pxd`
- [ ] [websocket] Enable picows auto-ping/auto-pong to remove the per-connection ping thread; update latency tracking via `measure_roundtrip_time()` or `notify_user_specific_pong_received()`. Est. lower CPU and fewer threads at scale. `src/mm_toolbox/websocket/connection.pyx`, `.venv/lib/python3.13/site-packages/picows/picows.pyx`
- [ ] [websocket] For non-fragmented frames, copy directly from `WSFrame.payload_ptr` into `BytesRingBufferFast.insert_char()` to avoid `bytes` materialization in the hot path. Est. 1.1x-1.4x on high message rates. `src/mm_toolbox/websocket/connection.pyx`, `src/mm_toolbox/ringbuffer/bytes.pyx`, `.venv/lib/python3.13/site-packages/picows/picows.pxd`
- [ ] [weights] Vectorize `ema_weights` with NumPy (avoid Python list comprehension) for large windows. Est. 3x-10x for large `window`. `src/mm_toolbox/weights/ema.py`
- [ ] [logging/advanced] Collapse worker flush into a single buffer (header + batch) and send with zero-copy ZMQ; remove the extra `internal_message_to_bytes` copy. Est. 1.4x-2.2x throughput (IPC-bound, small/medium messages). `src/mm_toolbox/logging/advanced/worker.pyx`, `src/mm_toolbox/logging/advanced/protocol.pyx`, `src/mm_toolbox/ringbuffer/ipc.py`
- [ ] [logging/advanced] Decode with `memoryview` slices and defer `bytes` materialization until handlers need it. Est. 1.15x-1.5x in decode-heavy paths. `src/mm_toolbox/logging/advanced/master.pyx`, `src/mm_toolbox/logging/advanced/protocol.pyx`
- [ ] [logging/advanced] Replace per-log worker name bytes with a worker id + lookup table to cut payload and memcpy. Est. 1.05x-1.25x (larger when names are long and logs are small). `src/mm_toolbox/logging/advanced/worker.pyx`, `src/mm_toolbox/logging/advanced/master.pyx`
- [ ] [logging/advanced] Filter by base log level in the worker before serialization to avoid wasted work. Est. 2x-8x when 70%+ logs are filtered; negligible when most logs pass. `src/mm_toolbox/logging/advanced/worker.pyx`
- [ ] [logging/advanced] Consider MPSC via per-producer SPSC SHM rings + fan-in consumer; define overflow policy (drop vs block). Est. 2x-4x for IPC portion; end-to-end ~1.3x-2.5x depending on serialization. `src/mm_toolbox/ringbuffer/shm/core.pyx`, `src/mm_toolbox/logging/advanced/worker.pyx`, `src/mm_toolbox/logging/advanced/master.pyx`
- [ ] [ringbuffer/bytes] `BytesRingBuffer` uniqueness checks are linear (`contains` on every insert); `insert_batch` can be O(n^2). Consider a set/hash index for large capacities. `src/mm_toolbox/ringbuffer/bytes.pyx:55`
